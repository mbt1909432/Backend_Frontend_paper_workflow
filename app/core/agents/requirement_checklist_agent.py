from typing import Dict, Any, Optional, Tuple
import re
from tenacity import (
    AsyncRetrying,
    retry_if_result,
    stop_after_attempt,
    wait_exponential,
    before_sleep_log,
    RetryError
)
from app.services.openai_service import OpenAIService
from app.utils.logger import logger


class RequirementChecklistAgent:
    """Requirement Checklist Generation Agent - ä¸“é—¨ç”Ÿæˆéœ€æ±‚æ¸…å•"""
    
    SYSTEM_PROMPT = """# Requirement Checklist Generation Agent

You are a specialized agent responsible for generating requirement checklists for paper writing.

## Your Task

Generate a comprehensive requirement checklist file: `requirements_checklist.md`

## Output File

**File Name**: `requirements_checklist.md` (Chinese)

## Input Files

1. Read `[Paper_Title]_[Paper_Type]_paper_overview.txt` to get:
   - Paper Title
   - Paper Type (Method or Survey)
   - Research content details

2. Optionally read `paper_framework.tex` (if exists) to understand paper structure

## Content Structure

### Header
è®ºæ–‡æ ‡é¢˜ (in English)

### Section 1: ç”»å›¾éœ€æ±‚ (Figure Requirements)

âš ï¸ **æ ¹æ®è®ºæ–‡ç±»å‹è°ƒæ•´å›¾è¡¨æ•°é‡:**
- **Methodç±»å‹**: å›¾è¡¨æ•°é‡è¾ƒå°‘ï¼Œé€šå¸¸2ä¸ªå›¾å³å¯ï¼ˆå¦‚ç³»ç»Ÿæ¶æ„å›¾ã€å®éªŒç»“æœå›¾ï¼‰
- **Surveyç±»å‹**: å›¾è¡¨æ•°é‡å¯ä»¥è¾ƒå¤šï¼Œç”¨äºå…¨é¢å±•ç¤ºç›¸å…³å·¥ä½œå’Œæ–¹æ³•å¯¹æ¯”

#### 1.1 ç®—æ³•å›¾/Motivationå›¾ (æ­£æ–‡ç”¨)
- [ ] ç³»ç»Ÿæ¶æ„å›¾ - å±•ç¤ºæ–¹æ³•æ¡†æ¶ï¼ˆæ”¾åœ¨Methodç« èŠ‚ï¼ŒMethodç±»å‹å¿…éœ€ï¼‰
- [ ] åŠ¨æœºå›¾ - å±•ç¤ºé—®é¢˜èƒŒæ™¯å’ŒåŠ¨æœºï¼ˆæ”¾åœ¨Introductionç« èŠ‚ï¼Œå¯é€‰ï¼‰
- [ ] ç®—æ³•æµç¨‹å›¾ - å±•ç¤ºå…³é”®ç®—æ³•æ­¥éª¤ï¼ˆæ”¾åœ¨Methodç« èŠ‚ï¼ŒMethodç±»å‹æ¨èï¼‰
- [ ] å…¶ä»–å¿…è¦çš„ç®—æ³•ç¤ºæ„å›¾ï¼ˆæ ¹æ®å®é™…éœ€è¦ï¼‰

#### 1.2 å®éªŒåˆ†æå›¾ (å®éªŒéƒ¨åˆ†ç”¨ï¼ŒMethodç±»å‹ä¸ºä¸»)
- [ ] ä¸»å®éªŒç»“æœå¯¹æ¯”å›¾ - ä¸baselineå¯¹æ¯”ï¼ˆæ”¾åœ¨Experimentsç« èŠ‚ï¼ŒMethodç±»å‹å¿…éœ€ï¼‰
- [ ] æ¶ˆèå®éªŒç»“æœå›¾ - å±•ç¤ºå„æ¨¡å—è´¡çŒ®ï¼ˆæ”¾åœ¨Experimentsç« èŠ‚ï¼ŒMethodç±»å‹æ¨èï¼‰
- [ ] å®šæ€§ç»“æœå±•ç¤º - å¯è§†åŒ–æ¡ˆä¾‹ï¼ˆæ”¾åœ¨Experimentsç« èŠ‚ï¼Œå¯é€‰ï¼‰
- [ ] å‚æ•°åˆ†æå›¾ - è¶…å‚æ•°å½±å“ï¼ˆæ”¾åœ¨Experimentsç« èŠ‚ï¼Œå¯é€‰ï¼‰

#### 1.3 Surveyç±»å‹ä¸“ç”¨å›¾è¡¨
- [ ] æ–¹æ³•åˆ†ç±»å¯¹æ¯”å›¾ - å±•ç¤ºä¸åŒæ–¹æ³•ç±»åˆ«ï¼ˆSurveyç±»å‹æ¨èï¼‰
- [ ] æ—¶é—´çº¿å›¾ - å±•ç¤ºé¢†åŸŸå‘å±•å†ç¨‹ï¼ˆSurveyç±»å‹æ¨èï¼‰
- [ ] æ–¹æ³•å¯¹æ¯”è¡¨æ ¼ - å…¨é¢å¯¹æ¯”å„ç§æ–¹æ³•ï¼ˆSurveyç±»å‹å¿…éœ€ï¼‰
- [ ] åº”ç”¨åœºæ™¯å›¾ - å±•ç¤ºä¸åŒåº”ç”¨é¢†åŸŸï¼ˆSurveyç±»å‹å¯é€‰ï¼‰

#### 1.4 è¡¨æ ¼
- [ ] ä¸»å®éªŒç»“æœè¡¨ - å¯¹æ¯”å„æ–¹æ³•æ€§èƒ½ï¼ˆMethodç±»å‹å¿…éœ€ï¼‰
- [ ] æ¶ˆèå®éªŒç»“æœè¡¨ - å„æ¨¡å—æ€§èƒ½å˜åŒ–ï¼ˆMethodç±»å‹æ¨èï¼‰
- [ ] æ•°æ®é›†ç»Ÿè®¡è¡¨ - æ•°æ®é›†åŸºæœ¬ä¿¡æ¯ï¼ˆMethodç±»å‹æ¨èï¼‰
- [ ] æ–¹æ³•å¯¹æ¯”è¡¨ - å…¨é¢å¯¹æ¯”å„ç§æ–¹æ³•ï¼ˆSurveyç±»å‹å¿…éœ€ï¼‰

### Section 2: æ–‡å­—éœ€æ±‚ (Text Requirements)

#### 2.1 ç¬¬ä¸€éƒ¨åˆ†: æ‘˜è¦ã€å¼•è¨€
- [ ] æ‘˜è¦ (Abstract): èƒŒæ™¯ã€é—®é¢˜ã€æ–¹æ³•ã€ç»“æœã€æ„ä¹‰
- [ ] å¼•è¨€ (Introduction): åŠ¨æœºã€ç°æœ‰æ–¹æ³•ã€å±€é™ã€è´¡çŒ®ã€è®ºæ–‡ç»„ç»‡

#### 2.2 ç¬¬äºŒéƒ¨åˆ†: æ–¹æ³•
- [ ] é—®é¢˜å®šä¹‰ - æ•°å­¦ç¬¦å·å®šä¹‰è¾“å…¥ã€è¾“å‡ºã€ç›®æ ‡
- [ ] æ–¹æ³•æ¡†æ¶ - æ•´ä½“æµç¨‹æè¿°ï¼ˆé…åˆæ¶æ„å›¾ï¼‰
- [ ] æ ¸å¿ƒæ¨¡å— - å„æ¨¡å—è¯¦ç»†è¯´æ˜å’Œå…¬å¼
- [ ] ç®—æ³•ä¼ªä»£ç  - å…³é”®ç®—æ³•æ­¥éª¤
- âš ï¸ ç”Ÿæˆçš„æ–¹æ³•è¦æ˜ç¡®ï¼ï¼ï¼

#### 2.3 ç¬¬ä¸‰éƒ¨åˆ†: å®éªŒåˆ†æ
- [ ] å®éªŒè®¾ç½® - æ•°æ®é›†ã€baselineã€è¯„ä¼°æŒ‡æ ‡ã€å®ç°ç»†èŠ‚
- [ ] ä¸»å®éªŒç»“æœ - ä¸baselineå¯¹æ¯”å’Œåˆ†æ
- [ ] æ¶ˆèå®éªŒ - å„æ¨¡å—è´¡çŒ®åˆ†æ
- [ ] ç»“æœè®¨è®º - å®éªŒå‘ç°å’ŒåŸå› åˆ†æ

## Requirements

1. **Be Specific**: Use actual dataset/model names from overview, not placeholders
2. **Be Concise**: Focus on essential requirements only
3. **Adjust by Paper Type**: 
   - Methodç±»å‹: å›¾è¡¨æ•°é‡è¾ƒå°‘ï¼ˆé€šå¸¸2ä¸ªå›¾å³å¯ï¼‰
   - Surveyç±»å‹: å›¾è¡¨æ•°é‡å¯ä»¥è¾ƒå¤šï¼ˆç”¨äºå…¨é¢å±•ç¤ºå’Œå¯¹æ¯”ï¼‰
4. **Based on Real Content**: Reference actual research content from overview file

## Workflow

1. Extract information from paper overview content (provided by orchestrator):
   - Paper Title
   - Paper Type (Method or Survey)
   - Research content details

2. Optionally use LaTeX paper content (if provided by orchestrator) to understand structure

3. Generate checklist based on Paper Type:
   - Method: Focus on method figures and experimental results
   - Survey: Include more comparison figures and tables

4. Use specific names from overview (datasets, models, etc.)

## Output Format

âš ï¸ **CRITICAL**: You cannot save files directly. You must output in the following markdown format:

```path
requirements_checklist.md
```

```markdown
# [Paper Title in English]

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“Š ç¬¬ä¸€å¤§ç±»: ç”»å›¾éœ€æ±‚
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

âš ï¸ **æ ¹æ®è®ºæ–‡ç±»å‹è°ƒæ•´å›¾è¡¨æ•°é‡:**
- **Methodç±»å‹**: å›¾è¡¨æ•°é‡è¾ƒå°‘ï¼Œé€šå¸¸2ä¸ªå›¾å³å¯ï¼ˆå¦‚ç³»ç»Ÿæ¶æ„å›¾ã€å®éªŒç»“æœå›¾ï¼‰
- **Surveyç±»å‹**: å›¾è¡¨æ•°é‡å¯ä»¥è¾ƒå¤šï¼Œç”¨äºå…¨é¢å±•ç¤ºç›¸å…³å·¥ä½œå’Œæ–¹æ³•å¯¹æ¯”

**1.1 ç®—æ³•å›¾/Motivationå›¾ (æ­£æ–‡ç”¨):**
- [ ] ç³»ç»Ÿæ¶æ„å›¾ - å±•ç¤ºæ–¹æ³•æ¡†æ¶ï¼ˆæ”¾åœ¨Methodç« èŠ‚ï¼ŒMethodç±»å‹å¿…éœ€ï¼‰
- [ ] åŠ¨æœºå›¾ - å±•ç¤ºé—®é¢˜èƒŒæ™¯å’ŒåŠ¨æœºï¼ˆæ”¾åœ¨Introductionç« èŠ‚ï¼Œå¯é€‰ï¼‰
- [ ] ç®—æ³•æµç¨‹å›¾ - å±•ç¤ºå…³é”®ç®—æ³•æ­¥éª¤ï¼ˆæ”¾åœ¨Methodç« èŠ‚ï¼ŒMethodç±»å‹æ¨èï¼‰
- [ ] å…¶ä»–å¿…è¦çš„ç®—æ³•ç¤ºæ„å›¾ï¼ˆæ ¹æ®å®é™…éœ€è¦ï¼‰

**1.2 å®éªŒåˆ†æå›¾ (å®éªŒéƒ¨åˆ†ç”¨ï¼ŒMethodç±»å‹ä¸ºä¸»):**
- [ ] ä¸»å®éªŒç»“æœå¯¹æ¯”å›¾ - ä¸baselineå¯¹æ¯”ï¼ˆæ”¾åœ¨Experimentsç« èŠ‚ï¼ŒMethodç±»å‹å¿…éœ€ï¼‰
- [ ] æ¶ˆèå®éªŒç»“æœå›¾ - å±•ç¤ºå„æ¨¡å—è´¡çŒ®ï¼ˆæ”¾åœ¨Experimentsç« èŠ‚ï¼ŒMethodç±»å‹æ¨èï¼‰
- [ ] å®šæ€§ç»“æœå±•ç¤º - å¯è§†åŒ–æ¡ˆä¾‹ï¼ˆæ”¾åœ¨Experimentsç« èŠ‚ï¼Œå¯é€‰ï¼‰
- [ ] å‚æ•°åˆ†æå›¾ - è¶…å‚æ•°å½±å“ï¼ˆæ”¾åœ¨Experimentsç« èŠ‚ï¼Œå¯é€‰ï¼‰

**1.3 Surveyç±»å‹ä¸“ç”¨å›¾è¡¨:**
- [ ] æ–¹æ³•åˆ†ç±»å¯¹æ¯”å›¾ - å±•ç¤ºä¸åŒæ–¹æ³•ç±»åˆ«ï¼ˆSurveyç±»å‹æ¨èï¼‰
- [ ] æ—¶é—´çº¿å›¾ - å±•ç¤ºé¢†åŸŸå‘å±•å†ç¨‹ï¼ˆSurveyç±»å‹æ¨èï¼‰
- [ ] æ–¹æ³•å¯¹æ¯”è¡¨æ ¼ - å…¨é¢å¯¹æ¯”å„ç§æ–¹æ³•ï¼ˆSurveyç±»å‹å¿…éœ€ï¼‰
- [ ] åº”ç”¨åœºæ™¯å›¾ - å±•ç¤ºä¸åŒåº”ç”¨é¢†åŸŸï¼ˆSurveyç±»å‹å¯é€‰ï¼‰

**1.4 è¡¨æ ¼:**
- [ ] ä¸»å®éªŒç»“æœè¡¨ - å¯¹æ¯”å„æ–¹æ³•æ€§èƒ½ï¼ˆMethodç±»å‹å¿…éœ€ï¼‰
- [ ] æ¶ˆèå®éªŒç»“æœè¡¨ - å„æ¨¡å—æ€§èƒ½å˜åŒ–ï¼ˆMethodç±»å‹æ¨èï¼‰
- [ ] æ•°æ®é›†ç»Ÿè®¡è¡¨ - æ•°æ®é›†åŸºæœ¬ä¿¡æ¯ï¼ˆMethodç±»å‹æ¨èï¼‰
- [ ] æ–¹æ³•å¯¹æ¯”è¡¨ - å…¨é¢å¯¹æ¯”å„ç§æ–¹æ³•ï¼ˆSurveyç±»å‹å¿…éœ€ï¼‰

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âœï¸ ç¬¬äºŒå¤§ç±»: æ–‡å­—éœ€æ±‚
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

**2.1 ç¬¬ä¸€éƒ¨åˆ†: æ‘˜è¦ã€å¼•è¨€**
- [ ] æ‘˜è¦ (Abstract): èƒŒæ™¯ã€é—®é¢˜ã€æ–¹æ³•ã€ç»“æœã€æ„ä¹‰
- [ ] å¼•è¨€ (Introduction): åŠ¨æœºã€ç°æœ‰æ–¹æ³•ã€å±€é™ã€è´¡çŒ®ã€è®ºæ–‡ç»„ç»‡

**2.2 ç¬¬äºŒéƒ¨åˆ†: æ–¹æ³•**
- [ ] é—®é¢˜å®šä¹‰ - æ•°å­¦ç¬¦å·å®šä¹‰è¾“å…¥ã€è¾“å‡ºã€ç›®æ ‡
- [ ] æ–¹æ³•æ¡†æ¶ - æ•´ä½“æµç¨‹æè¿°ï¼ˆé…åˆæ¶æ„å›¾ï¼‰
- [ ] æ ¸å¿ƒæ¨¡å— - å„æ¨¡å—è¯¦ç»†è¯´æ˜å’Œå…¬å¼
- [ ] ç®—æ³•ä¼ªä»£ç  - å…³é”®ç®—æ³•æ­¥éª¤
- âš ï¸ ç”Ÿæˆçš„æ–¹æ³•è¦æ˜ç¡®ï¼ï¼ï¼

**2.3 ç¬¬ä¸‰éƒ¨åˆ†: å®éªŒåˆ†æ**
- [ ] å®éªŒè®¾ç½® - æ•°æ®é›†ã€baselineã€è¯„ä¼°æŒ‡æ ‡ã€å®ç°ç»†èŠ‚
- [ ] ä¸»å®éªŒç»“æœ - ä¸baselineå¯¹æ¯”å’Œåˆ†æ
- [ ] æ¶ˆèå®éªŒ - å„æ¨¡å—è´¡çŒ®åˆ†æ
- [ ] ç»“æœè®¨è®º - å®éªŒå‘ç°å’ŒåŸå› åˆ†æ
```

**Important**:
- Use ` ```path ` to specify the file name
- Use ` ```markdown ` to specify the markdown content
- The orchestrator will parse this markdown and save the file
- Do NOT include any file operations in your response"""

    def __init__(self, openai_service: OpenAIService):
        self.openai_service = openai_service
    
    def _parse_markdown_output(self, response: str) -> Tuple[Optional[str], Optional[str]]:
        """
        è§£æ Agent è¾“å‡ºçš„ markdown æ ¼å¼
        
        æœŸæœ›æ ¼å¼:
        ```path
        requirements_checklist.md
        ```
        
        ```markdown
        [content]
        ```
        
        Returns:
            (file_name, file_content) æˆ– (None, None) å¦‚æœè§£æå¤±è´¥
        """
        # æå– path å—ä¸­çš„æ–‡ä»¶åï¼ˆæ›´å®½æ¾çš„åŒ¹é…ï¼Œæ”¯æŒå¤šç§æ ¼å¼ï¼‰
        # æ”¯æŒ ```path\n...\n``` æˆ– ```path ... ```ï¼ˆåŒä¸€è¡Œï¼‰
        path_pattern = r'```path\s*\n?(.*?)\n?```'
        path_match = re.search(path_pattern, response, re.DOTALL)
        
        if not path_match:
            logger.warning("No ```path block found in agent output")
            return None, None
        
        file_name = path_match.group(1).strip()
        
        # æå– markdown å—ä¸­çš„å†…å®¹ï¼ˆæ›´å®½æ¾çš„åŒ¹é…ï¼‰
        markdown_pattern = r'```markdown\s*\n?(.*?)\n?```'
        markdown_match = re.search(markdown_pattern, response, re.DOTALL)
        
        if not markdown_match:
            logger.warning("No ```markdown block found in agent output")
            return None, None
        
        file_content = markdown_match.group(1).strip()
        
        return file_name, file_content
    
    async def _generate_requirement_checklist_attempt(
        self,
        paper_overview: str,
        latex_content: Optional[str],
        user_original_input: Optional[str],
        temperature: float,
        max_tokens: int,
        model: Optional[str],
        attempt_number: int = 1
    ) -> Optional[Dict[str, Any]]:
        """
        å•æ¬¡ç”Ÿæˆå°è¯•ï¼ˆå†…éƒ¨æ–¹æ³•ï¼Œç”¨äºé‡è¯•ï¼‰
        
        Args:
            paper_overview: ä» Paper Overview Agent å¾—åˆ°çš„æ–‡æœ¬å†…å®¹
            latex_content: ä» LaTeX Paper Generator Agent å¾—åˆ°çš„ LaTeX å†…å®¹
            user_original_input: ç”¨æˆ·åŸå§‹è¾“å…¥
            temperature: æ¸©åº¦å‚æ•°
            max_tokens: æœ€å¤§tokenæ•°
            model: æ¨¡å‹åç§°
            attempt_number: å½“å‰å°è¯•æ¬¡æ•°
            
        Returns:
            æˆåŠŸæ—¶è¿”å›ç»“æœå­—å…¸ï¼Œå¤±è´¥æ—¶è¿”å› None
        """
        # é‡è¯•æ—¶é™ä½ temperature ä»¥æé«˜ç¨³å®šæ€§
        adjusted_temperature = max(0.3, temperature - (attempt_number - 1) * 0.1)
        
        # æ„å»ºç”¨æˆ·æ¶ˆæ¯
        user_content = f"""Please generate a requirement checklist based on the following information:

## Paper Overview (from Agent 1):
{paper_overview}

"""
        
        # å¦‚æœæä¾›äº† LaTeX å†…å®¹ï¼Œåˆ™ä½¿ç”¨å®ƒ
        if latex_content:
            user_content += f"""
## LaTeX Paper Content (from Agent 2):
{latex_content}

"""
        # å¦‚æœ Agent 2 è·³è¿‡äº†ï¼Œä½¿ç”¨ç”¨æˆ·åŸå§‹è¾“å…¥
        elif user_original_input:
            user_content += f"""
## User Original Input (Agent 2 was skipped):
{user_original_input}

"""
        
        user_content += """
Please generate a comprehensive requirement checklist based on the paper overview and structure information above."""
        
        # é‡è¯•æ—¶å¢å¼ºæ ¼å¼è¦æ±‚æç¤º
        if attempt_number > 1:
            user_content += "\n\nâš ï¸ IMPORTANT: You MUST output in the exact format with ```path and ```markdown blocks. Ensure both blocks are present and properly formatted."
        
        # æ„å»ºæ¶ˆæ¯
        messages = [
            {
                "role": "system",
                "content": self.SYSTEM_PROMPT
            },
            {
                "role": "user",
                "content": user_content
            }
        ]
        
        # è°ƒç”¨ OpenAI
        raw_response, usage = await self.openai_service.chat_completion(
            messages=messages,
            temperature=adjusted_temperature,
            max_tokens=max_tokens,
            model=model
        )
        
        # è§£æè¾“å‡º
        file_name, file_content = self._parse_markdown_output(raw_response)
        
        if file_name is None or file_content is None:
            logger.warning(f"Attempt {attempt_number}: Failed to parse agent output")
            return None
        
        logger.info(f"Requirement checklist generated successfully on attempt {attempt_number}: {file_name}")
        
        return {
            "file_name": file_name,
            "file_content": file_content,
            "raw_response": raw_response,
            "usage": usage
        }
    
    async def generate_requirement_checklist(
        self,
        paper_overview: str,
        latex_content: Optional[str] = None,
        user_original_input: Optional[str] = None,
        temperature: float = 0.7,
        max_tokens: int = 4000,
        model: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        ç”Ÿæˆéœ€æ±‚æ¸…å•ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
        
        Args:
            paper_overview: ä» Paper Overview Agent å¾—åˆ°çš„æ–‡æœ¬å†…å®¹
            latex_content: ä» LaTeX Paper Generator Agent å¾—åˆ°çš„ LaTeX å†…å®¹ï¼ˆå¦‚æœ Agent 2 æ²¡æœ‰è·³è¿‡ï¼‰
            user_original_input: ç”¨æˆ·åŸå§‹è¾“å…¥ï¼ˆå¦‚æœ Agent 2 SKIPPED åˆ™ä½¿ç”¨æ­¤è¾“å…¥ï¼‰
            temperature: æ¸©åº¦å‚æ•°
            max_tokens: æœ€å¤§tokenæ•°
            model: æ¨¡å‹åç§°
            
        Returns:
            {
                "file_name": str,
                "file_content": str,
                "raw_response": str,
                "usage": dict
            }
            
        Raises:
            ValueError: å¦‚æœæ‰€æœ‰é‡è¯•éƒ½å¤±è´¥
        """
        def is_parse_failed(result: Optional[Dict[str, Any]]) -> bool:
            """æ£€æŸ¥è§£ææ˜¯å¦å¤±è´¥"""
            return result is None
        
        attempt_number = 1
        last_result = None
        
        try:
            async for attempt in AsyncRetrying(
                stop=stop_after_attempt(3),
                retry=retry_if_result(is_parse_failed),
                wait=wait_exponential(multiplier=1, min=2, max=10),
                before_sleep=before_sleep_log(logger, logger.warning)
            ):
                with attempt:
                    last_result = await self._generate_requirement_checklist_attempt(
                        paper_overview=paper_overview,
                        latex_content=latex_content,
                        user_original_input=user_original_input,
                        temperature=temperature,
                        max_tokens=max_tokens,
                        model=model,
                        attempt_number=attempt_number
                    )
                    attempt_number += 1
                    if last_result is None:
                        # è§¦å‘é‡è¯•
                        raise ValueError("Parse failed, will retry")
                    return last_result
        except RetryError:
            # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥
            logger.error(f"Failed to generate requirement checklist after {attempt_number - 1} attempts")
            raise ValueError("Agent output format is invalid after multiple retries. Expected markdown format with ```path and ```markdown blocks.")
        
        # å¦‚æœ somehow åˆ°è¾¾è¿™é‡Œï¼Œè¿”å›æœ€åçš„ç»“æœ
        if last_result is None:
            raise ValueError("Agent output format is invalid. Expected markdown format with ```path and ```markdown blocks.")
        return last_result
    
    async def generate_requirement_checklist_stream(
        self,
        paper_overview: str,
        latex_content: Optional[str] = None,
        user_original_input: Optional[str] = None,
        temperature: float = 0.7,
        max_tokens: int = 4000,
        model: Optional[str] = None
    ):
        """
        æµå¼ç”Ÿæˆéœ€æ±‚æ¸…å•
        
        Args:
            paper_overview: ä» Paper Overview Agent å¾—åˆ°çš„æ–‡æœ¬å†…å®¹
            latex_content: ä» LaTeX Paper Generator Agent å¾—åˆ°çš„ LaTeX å†…å®¹ï¼ˆå¦‚æœ Agent 2 æ²¡æœ‰è·³è¿‡ï¼‰
            user_original_input: ç”¨æˆ·åŸå§‹è¾“å…¥ï¼ˆå¦‚æœ Agent 2 SKIPPED åˆ™ä½¿ç”¨æ­¤è¾“å…¥ï¼‰
            temperature: æ¸©åº¦å‚æ•°
            max_tokens: æœ€å¤§tokenæ•°
            model: æ¨¡å‹åç§°
            
        Returns:
            OpenAI æµå¼å“åº”è¿­ä»£å™¨
        """
        # æ„å»ºç”¨æˆ·æ¶ˆæ¯
        user_content = f"""Please generate a requirement checklist based on the following information:

## Paper Overview (from Agent 1):
{paper_overview}

"""
        
        # å¦‚æœæä¾›äº† LaTeX å†…å®¹ï¼Œåˆ™ä½¿ç”¨å®ƒ
        if latex_content:
            user_content += f"""
## LaTeX Paper Content (from Agent 2):
{latex_content}

"""
        # å¦‚æœ Agent 2 è·³è¿‡äº†ï¼Œä½¿ç”¨ç”¨æˆ·åŸå§‹è¾“å…¥
        elif user_original_input:
            user_content += f"""
## User Original Input (Agent 2 was skipped):
{user_original_input}

"""
        
        user_content += """
Please generate a comprehensive requirement checklist based on the paper overview and structure information above."""
        
        # æ„å»ºæ¶ˆæ¯
        messages = [
            {
                "role": "system",
                "content": self.SYSTEM_PROMPT
            },
            {
                "role": "user",
                "content": user_content
            }
        ]
        
        # è°ƒç”¨ OpenAI æµå¼æ¥å£
        stream = await self.openai_service.chat_completion_stream(
            messages=messages,
            temperature=temperature,
            max_tokens=max_tokens,
            model=model
        )
        
        return stream

