from typing import List, Dict, Any, Optional, AsyncIterator, Union
from anthropic import AsyncAnthropic
from app.config.settings import settings
from app.utils.logger import logger
import base64
import tiktoken


class AnthropicService:
    """Anthropic æœåŠ¡å°è£… - æ”¯æŒå¤šæ¨¡æ€è¾“å…¥ï¼ˆæ–‡æœ¬+å›¾ç‰‡ï¼‰"""
    
    def __init__(self):
        if not settings.anthropic_api_key:
            raise ValueError("ANTHROPIC_API_KEY is not set in environment variables")
        
        # å¦‚æœé…ç½®äº†è‡ªå®šä¹‰ endpointï¼Œåˆ™ä½¿ç”¨å®ƒï¼ˆç”¨äºæ¨¡å‹è½¬å‘å•†ï¼‰
        client_kwargs = {"api_key": settings.anthropic_api_key}
        if settings.anthropic_api_base:
            client_kwargs["base_url"] = settings.anthropic_api_base
            logger.info(f"Using custom Anthropic API endpoint: {settings.anthropic_api_base}")
        
        self.client = AsyncAnthropic(**client_kwargs)
        self.default_model = settings.anthropic_model
        self.default_temperature = settings.anthropic_temperature
        self.default_max_tokens = settings.anthropic_max_tokens
        print(f"anthropicğŸ˜€{client_kwargs}")
    
    def _count_tokens(self, text: str, model: Optional[str] = None) -> int:
        """ä½¿ç”¨ tiktoken ç»Ÿè®¡ token æ•°ï¼ˆä¼˜å…ˆæŒ‰æ¨¡å‹ç¼–ç ï¼Œå¤±è´¥åˆ™å›é€€åˆ°é€šç”¨ç¼–ç ï¼‰"""
        try:
            encoding = tiktoken.encoding_for_model(model or self.default_model)
        except Exception:
            encoding = tiktoken.get_encoding("cl100k_base")
        return len(encoding.encode(text))
    
    def _format_messages_for_log(self, messages: List[Dict[str, Any]]) -> str:
        """æ ¼å¼åŒ–æ¶ˆæ¯åˆ—è¡¨ç”¨äºæ—¥å¿—è¾“å‡º"""
        formatted = []
        for msg in messages:
            role = msg.get("role", "unknown")
            content = msg.get("content", "")
            
            # å¤„ç†å¤šæ¨¡æ€å†…å®¹
            if isinstance(content, list):
                content_parts = []
                for part in content:
                    if isinstance(part, dict):
                        if part.get("type") == "text":
                            full_text = part.get("text", "")
                            if len(full_text) > 500:
                                total_tokens = self._count_tokens(full_text)
                                text_preview = full_text[:500] + f"\n... (truncated, total tokens: {total_tokens})"
                            else:
                                text_preview = full_text
                            content_parts.append(f"[text: {text_preview}]")
                        elif part.get("type") == "image":
                            source = part.get("source", {})
                            media_type = source.get("media_type", "unknown")
                            data_preview = source.get("data", "")[:50] + "..." if source.get("data") else "N/A"
                            content_parts.append(f"[image: {media_type}, data: {data_preview}]")
                    else:
                        content_parts.append(str(part)[:200])
                content_str = " ".join(content_parts)
            else:
                full_content_str = str(content)
                if len(full_content_str) > 200:
                    total_tokens = self._count_tokens(full_content_str)
                    content_str = full_content_str[:200] + f"\n... (truncated, total tokens: {total_tokens})"
                else:
                    content_str = full_content_str
            
            formatted.append(f"  {role}: {content_str}")
        return "\n".join(formatted)
    
    @staticmethod
    def encode_image_to_base64(image_data: bytes, media_type: str = "image/jpeg") -> str:
        """
        å°†å›¾ç‰‡æ•°æ®ç¼–ç ä¸º base64 å­—ç¬¦ä¸²
        
        Args:
            image_data: å›¾ç‰‡çš„äºŒè¿›åˆ¶æ•°æ®
            media_type: å›¾ç‰‡ç±»å‹ (image/jpeg, image/png, image/gif, image/webp)
            
        Returns:
            base64 ç¼–ç çš„å­—ç¬¦ä¸²
        """
        return base64.b64encode(image_data).decode("utf-8")
    
    @staticmethod
    def create_image_block(image_data: bytes, media_type: str = "image/jpeg") -> Dict[str, Any]:
        """
        åˆ›å»ºå›¾ç‰‡å†…å®¹å—
        
        Args:
            image_data: å›¾ç‰‡çš„äºŒè¿›åˆ¶æ•°æ®
            media_type: å›¾ç‰‡ç±»å‹ (image/jpeg, image/png, image/gif, image/webp)
            
        Returns:
            å›¾ç‰‡å†…å®¹å—å­—å…¸
        """
        base64_data = AnthropicService.encode_image_to_base64(image_data, media_type)
        return {
            "type": "image",
            "source": {
                "type": "base64",
                "media_type": media_type,
                "data": base64_data
            }
        }
    
    @staticmethod
    def create_text_block(text: str) -> Dict[str, Any]:
        """
        åˆ›å»ºæ–‡æœ¬å†…å®¹å—
        
        Args:
            text: æ–‡æœ¬å†…å®¹
            
        Returns:
            æ–‡æœ¬å†…å®¹å—å­—å…¸
        """
        return {
            "type": "text",
            "text": text
        }
    
    async def messages_create(
        self,
        messages: List[Dict[str, Any]],
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None,
        model: Optional[str] = None,
        system: Optional[str] = None
    ) -> tuple[str, Dict[str, Any]]:
        """
        éæµå¼æ¶ˆæ¯åˆ›å»ºï¼ˆæ”¯æŒå¤šæ¨¡æ€ï¼‰
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨ï¼Œæ¯ä¸ªæ¶ˆæ¯çš„ content å¯ä»¥æ˜¯å­—ç¬¦ä¸²æˆ–åˆ—è¡¨ï¼ˆå¤šæ¨¡æ€ï¼‰
            temperature: æ¸©åº¦å‚æ•°
            max_tokens: æœ€å¤§tokenæ•°
            model: æ¨¡å‹åç§°
            
        Returns:
            (response_text, usage_info)
        """
        try:
            # æ‰“å° prompt
            logger.info("=" * 80)
            logger.info("Anthropic API Request (Prompt):")
            logger.info(f"Model: {model or self.default_model}")
            logger.info(f"Temperature: {temperature if temperature is not None else self.default_temperature}")
            logger.info(f"Max Tokens: {max_tokens or self.default_max_tokens}")
            logger.info("Messages:")
            logger.info(self._format_messages_for_log(messages))
            logger.info("ğŸ˜€" * 80)
            
            create_kwargs = {
                "model": model or self.default_model,
                "messages": messages,
                "temperature": temperature if temperature is not None else self.default_temperature,
                "max_tokens": max_tokens or self.default_max_tokens
            }
            if system:
                create_kwargs["system"] = system
            
            response = await self.client.messages.create(**create_kwargs)
            
            # æå–å“åº”æ–‡æœ¬
            response_text = ""
            if response.content:
                for block in response.content:
                    if block.type == "text":
                        response_text += block.text
            
            usage_info = {
                "input_tokens": response.usage.input_tokens,
                "output_tokens": response.usage.output_tokens,
                "total_tokens": response.usage.input_tokens + response.usage.output_tokens
            }
            
            # æ‰“å° output
            logger.info("=" * 80)
            logger.info("Anthropic API Response (Output):")
            if len(response_text) > 2000:
                total_tokens = self._count_tokens(response_text, model)
                output_preview = response_text[:2000] + f"\n... (truncated, total tokens: {total_tokens})"
                logger.info(output_preview)
            else:
                logger.info(response_text)
            logger.info(f"Usage: {usage_info['total_tokens']} tokens (input: {usage_info['input_tokens']}, output: {usage_info['output_tokens']})")
            logger.info("=" * 80)
            
            return response_text, usage_info
            
        except Exception as e:
            logger.error(f"Anthropic API error: {str(e)}")
            raise
    
    async def messages_create_stream(
        self,
        messages: List[Dict[str, Any]],
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None,
        model: Optional[str] = None,
        system: Optional[str] = None
    ) -> AsyncIterator:
        """
        æµå¼æ¶ˆæ¯åˆ›å»ºï¼ˆæ”¯æŒå¤šæ¨¡æ€ï¼‰
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨ï¼Œæ¯ä¸ªæ¶ˆæ¯çš„ content å¯ä»¥æ˜¯å­—ç¬¦ä¸²æˆ–åˆ—è¡¨ï¼ˆå¤šæ¨¡æ€ï¼‰
            temperature: æ¸©åº¦å‚æ•°
            max_tokens: æœ€å¤§tokenæ•°
            model: æ¨¡å‹åç§°
            
        Returns:
            Anthropic æµå¼å“åº”è¿­ä»£å™¨
        """
        try:
            # æ‰“å° prompt
            logger.info("=" * 80)
            logger.info("Anthropic API Request (Prompt) - Streaming:")
            logger.info(f"Model: {model or self.default_model}")
            logger.info(f"Temperature: {temperature if temperature is not None else self.default_temperature}")
            logger.info(f"Max Tokens: {max_tokens or self.default_max_tokens}")
            logger.info("Messages:")
            logger.info(self._format_messages_for_log(messages))
            logger.info("=" * 80)
            
            create_kwargs = {
                "model": model or self.default_model,
                "messages": messages,
                "temperature": temperature if temperature is not None else self.default_temperature,
                "max_tokens": max_tokens or self.default_max_tokens,
                "stream": True
            }
            if system:
                create_kwargs["system"] = system
            
            stream = await self.client.messages.create(**create_kwargs)
            
            # åŒ…è£…æµå¼å“åº”ï¼Œæ”¶é›†å®Œæ•´è¾“å‡º
            accumulated_text = ""
            usage_info = None
            
            async def wrapped_stream():
                nonlocal accumulated_text, usage_info
                try:
                    async for chunk in stream:
                        # å¤„ç†ä¸åŒç±»å‹çš„ chunk
                        chunk_type = getattr(chunk, 'type', None)
                        
                        # æ”¶é›†å†…å®¹
                        if chunk_type == 'content_block_delta':
                            delta = getattr(chunk, 'delta', None)
                            if delta:
                                text = getattr(delta, 'text', None)
                                if text:
                                    accumulated_text += text
                        
                        # æ£€æŸ¥æ˜¯å¦æœ‰ usage ä¿¡æ¯
                        if chunk_type == 'message_delta' or chunk_type == 'message_stop':
                            usage = getattr(chunk, 'usage', None)
                            if usage:
                                usage_info = {
                                    "input_tokens": getattr(usage, 'input_tokens', 0),
                                    "output_tokens": getattr(usage, 'output_tokens', 0),
                                    "total_tokens": getattr(usage, 'input_tokens', 0) + getattr(usage, 'output_tokens', 0)
                                }
                        
                        yield chunk
                    
                    # æµç»“æŸåæ‰“å°å®Œæ•´è¾“å‡º
                    logger.info("=" * 80)
                    logger.info("Anthropic API Response (Output) - Streaming Complete:")
                    if len(accumulated_text) > 2000:
                        total_tokens = self._count_tokens(accumulated_text, model)
                        output_preview = accumulated_text[:2000] + f"\n... (truncated, total tokens: {total_tokens})"
                        logger.info(output_preview)
                    else:
                        logger.info(accumulated_text)
                    if usage_info:
                        logger.info(f"Usage: {usage_info['total_tokens']} tokens (input: {usage_info['input_tokens']}, output: {usage_info['output_tokens']})")
                    else:
                        logger.info("Usage: N/A (not provided in stream)")
                    logger.info("=" * 80)
                    
                except Exception as e:
                    logger.error(f"Error in streaming: {str(e)}")
                    raise
            
            logger.info("Anthropic streaming started")
            # è¿”å›å¼‚æ­¥ç”Ÿæˆå™¨å¯¹è±¡ï¼ˆå¯ä»¥ç›´æ¥ç”¨äº async forï¼‰
            return wrapped_stream()
            
        except Exception as e:
            logger.error(f"Anthropic streaming error: {str(e)}")
            raise

